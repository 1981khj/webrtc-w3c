<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta name="generator" content=
  "HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org" />
  <link href="getusermedia.css" rel="stylesheet" type="text/css" />
  <link href="ReSpec.js/css/respec.css" rel="stylesheet" type=
  "text/css" />

  <title>getusermedia</title>
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8' /><!-- 
      === NOTA BENE ===
      For the three scripts below, if your spec resides on dev.w3 you can check them
      out in the same tree and use relative links so that they'll work offline.

      To generate the dated version of the specification:

           Open this doc in Mozilla. 

           Do a CTRL-ALT-SHIFT-S

           Select "XHMTL( source)" from dialog box. This will pop a new tab with
           genreated version of the document.

           This will open a new tab with generated html. Copy and paste this to
           a new file. Note if you use Chrome or Safari, this step will not
           work. What will happen is the paste will have th original document,
           not what was displayed in the window that you did the copy on.

           Rename the new file to the correct day such as
           getusermedia-20111003.html then search for and edit the links for
           "This version" and "Previos version". Add the new file into git and
           check in. 

           Once everyone is happy, the getusermedia.html and
           getusermedia-20111003.html files can be coppied to
           getusermedia.html and getusermedia-20111003.html
           respectively in the ../editor/. W3C directory. 

     -->

  <script src='http://dev.w3.org/2009/dap/ReSpec.js/js/respec.js' class='remove' type=
  "text/javascript">
</script>

  <script class='remove' type="text/javascript">
//<![CDATA[
      var respecConfig = {
          previousURI: "-",
          // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
          specStatus:           "ED",

         // the specification's short name, as in http://www.w3.org/TR/short-name/
          shortName:            "getusermedia",
          // if your specification has a subtitle that goes below the main
          // formal title, define it here
          // subtitle   :  "an excellent document",

          // if you wish the publication date to be other than today, set this
          // publishDate:  "2009-08-06",

          // new ability to override the copyright completely
                  overrideCopyright:  "<p class='copyright'>Initial Author of this Specification was Ian Hickson, Google Inc., with the following copyright statement:<br /> &#169; Copyright 2004-2011 Apple Computer, Inc., Mozilla Foundation, and Opera Software ASA. You are granted a license to use, reproduce and create derivative works of this document.</p> <p class='copyright'>All subsequent changes since 26 July 2011 done by the W3C WebRTC Working Group are under the following <a href='http://www.w3.org/Consortium/Legal/ipr-notice#Copyright'>Copyright</a>:<br />&#169; 2011 <a href='http://www.w3.org/'><acronym title='World Wide Web Consortium'>W3C</acronym></a><sup>&#174;</sup> (<a href='http://www.csail.mit.edu/'><acronym title='Massachusetts Institute of Technology'>MIT</acronym></a>, <a href='http://www.ercim.eu/'><acronym title='European Research Consortium for Informatics and Mathematics'>ERCIM</acronym></a>, <a href='http://www.keio.ac.jp/'>Keio</a>), All Rights Reserved. <a href='http://www.w3.org/Consortium/Legal/copyright-documents'>Document use</a>  rules apply.</p> <p class='copyright'>For the entire publication on the W3C site the <a href='http://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer'>liability</a> and <a href='http://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks'>trademark</a> rules apply.</p>",


          // if the specification's copyright date is a range of years, specify
          // the start date here:
          // copyrightStart: "2005",

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
          // previousPublishDate:  "1977-03-15",
          // previousMaturity:  "WD",

          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "http://dev.w3.org/2011/webrtc/editor/getusermedia.html",

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2009-08-05",

          // if you want to have extra CSS, append them to this list
          // it is recommended that the respec.css stylesheet be kept
          extraCSS:             ["http://dev.w3.org/2009/dap/ReSpec.js/css/respec.css"],
  //          extraCSS:             ["../../../2009/dap/ReSpec.js/css/respec.css"],

          // editors, add as many as you like
          // only "name" is required
          editors:  [
  //              { name: "Your Name", url: "http://example.org/",
  //                company: "Your Company", companyURL: "http://example.com/" },
              { name: "Adam Bergkvist", company: "Ericsson" },
              { name: "Daniel C. Burnett", company: "Voxeo" },
              { name: "Cullen Jennings", company: "Cisco" },
              { name: "Anant Narayanan", company: "Mozilla" },
          ],

          // authors, add as many as you like. 
          // This is optional, uncomment if you have authors as well as editors.
          // only "name" is required. Same format as editors.

          //authors:  [
          //    { name: "Your Name", url: "http://example.org/",
          //      company: "Your Company", companyURL: "http://example.com/" },
          //],
          
          // name of the WG
          wg:           "Web Real-Time Communications Working Group",
          
          // URI of the public WG page
          wgURI:        "http://www.w3.org/2011/04/webrtc/",
          
          // name (with the @w3c.org) of the public mailing to which comments are due
          wgPublicList: "public-webrtc@w3.org",
          
          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "",
      };
  //]]>
  </script>
</head>

<body>
  <section id="abstract">

    <p>This document defines a set of APIs that allow local media,
    including audio and video, to be requested from a platform.
    </p>
  </section>

 <section id="sotd">
   <p>This document is not complete.
   It is subject to major changes and, while early experimentations are
   encouraged, it is therefore not intended for implementation. The API
   is based on preliminary work done in the WHATWG. The Web Real-Time
   Communications Working Group expects this specification to evolve
   significantly based on:</p>
  <ul>
    <li>Privacy issues that arise when exposing local capabilities and
    local streams.</li>
    <li>Technical discussions within the group.</li>
    <li>Experience gained through early experimentations.</li>
    <li>Feedback received from other groups and individuals.</li>
  </ul>
  
</section> 

  <section id="intro" class="informative">
  <h2>Introduction</h2>

  <p>Access to multimedia streams (video, audio, or both) from local devices (video
    cameras, microphones, Web cams) can have a number of uses, such as real-time 
    communication, recording, surveillance.</p>

  <p>This document defines the APIs used to get access to local devices (video
    cameras, microphones, Web cams) that can generate multimedia stream data. </p>
  </section>

  <section id="local-content">
  <h2>Obtaining local multimedia content</h2>

  <section id="local-content-definition">
  <h3>Definition</h3>

  <section>
  <h2>NavigatorUserMedia</h2>

  <dl title='[NoInterfaceObject] interface NavigatorUserMedia' class='idl'>
    <dt>void getUserMedia(in MediaStreamOptions? options, in NavigatorUserMediaSuccessCallback?
    successCallback, in optional NavigatorUserMediaErrorCallback? errorCallback)</dt>

    <dd>
      <p>Prompts the user for permission to use their Web cam or other video or audio
      input.</p>

      <p>The <var title="">options</var> argument is an object of type
      <code title="">MediaStreamOptions</code>. The object can contain
      the following boolean properties:
      </p>

      <dl>
        <dt>"<code title="">audio</code>"</dt>
        <dd>The provided media needs to include audio data.</dd>

        <dt>"<code title="">video</code>"</dt>
        <dd>The provided media needs to include video data.</dd>
      </dl>

      <p>If the user accepts, the <var title="">successCallback</var> is invoked, with a
      suitable <code><a href="#localmediastream">LocalMediaStream</a></code> object as
      its argument.</p>

      <p>If the user declines, the <var title="">errorCallback</var> (if any) is
      invoked.</p>

      <p>When the <a href=
      "#widl-NavigatorUserMedia-getUserMedia-void-DOMString-options-NavigatorUserMediaSuccessCallback-successCallback-NavigatorUserMediaErrorCallback-errorCallback">
      <code>getUserMedia()</code></a> method is called, the user agent must run the
      following steps:</p>

      <ol>
        <li>
          <p>Let <var title="">options</var> be the method's first argument.</p>
        </li>

        <li>
          <p>Let <var title="">successCallback</var> be the callback indicated by the
          method's second argument.</p>
        </li>

        <li>
          <p>Let <var title="">errorCallback</var> be the callback indicated by the
          method's third argument, if any, or null otherwise.</p>
        </li>

        <li>
          <p>If <var title="">successCallback</var> is null, abort these steps.</p>
        </li><!-- we could throw an exception instead (that's
   why the method doesn't return until later: so that we can add an
   exception here, or for /options/ below, without changing the
   algorithm) -->

        <li>
          <p>Let <var title="">audio</var> be true.</p>
        </li>

        <li>
          <p>Let <var title="">video</var> be true.</p>
        </li>

        <li>
          <p>If the <var title="">audio</var> property in <var title="">options</var>
          is present and set to false, let <var title="">audio</var> be false.</p>
        </li>

        <li>
          <p>If the <var title="">video</var> property in <var title="">options</var>
          is present and set to false, let <var title="">video</var> be false.</p>
        </li>

        <li>
          <p>If both <var title="">audio</var> and <var title="">video</var> are still
          false, then throw a <code>NOT_SUPPORTED_ERR</code> exception and abort these
          steps.</p>
        </li>

        <li>
          <p>Return, and run the remaining steps asynchronously.</p>
        </li>

        <li>
          <p>Optionally, e.g. based on a previously-established user preference, for
          security reasons, or due to platform limitations, jump to the step labeled
          <em>failure</em> below.</p>
        </li>

        <li>
          <p>Prompt the user in a user-agent-specific manner for permission to provide
          the entry script's origin with a <code><a href=
          "#localmediastream">LocalMediaStream</a></code> object representing a media
          stream.</p>

          <p>If <var title="">audio</var> is true, then the provided media should include
          an audio track. If <var title="">audio</var> is false, then the provided media
          must not include an audio track.</p>

          <p>If <var title="">video</var> is true, then the provided media should include
          a video track. If <var title="">video</var> is false, then the provided media
          must not include a video track.</p>

          <p>User agents are encouraged to default to using the user's primary or system
          default camera and/or microphone (as appropriate) to generate the media stream.
          User agents may allow users to use any media source, including pre-recorded
          media files.</p>

          <p>User agents may wish to offer the user more control over the provided media.
          For example, a user agent could offer to enable a camera light or flash, or to
          change settings such as the frame rate or shutter speed.</p>

          <p>If the user grants permission to use local recording devices, user agents
          are encouraged to include a prominent indicator that the devices are "hot"
          (i.e. an "on-air" or "recording" indicator).</p>

          <p>If the user denies permission, jump to the step labeled <em>failure</em>
          below. If the user never responds, this algorithm stalls on this step.</p>
        </li>

        <li>
          <p>Let <var title="">stream</var> be the <code><a href=
          "#localmediastream">LocalMediaStream</a></code> object for which the user
          granted permission.</p>
        </li>

        <li>
          <p>Queue a task to invoke <var title="">successCallback</var> with
          <var title="">stream</var> as its argument.</p>
        </li>

        <li>
          <p>Abort these steps.</p>
        </li>

        <li>
          <p><em>Failure</em>: If <var title="">errorCallback</var> is null, abort these
          steps.</p>
        </li>

        <li>
          <p>Let <var title="">error</var> be a new <code><a href=
          "#navigatorusermediaerror">NavigatorUserMediaError</a></code> object whose
          <code title="dom-NavigatorUserMediaError-code"><a href=
          "#dom-navigatorusermediaerror-code">code</a></code> attribute has the numeric
          value 1 (<code title="dom-NavigatorUserMediaError-PERMISSION_DENIED"><a href=
          "#dom-navigatorusermediaerror-permission_denied">PERMISSION_DENIED</a></code>).</p>
        </li>

        <li>
          <p>Queue a task to invoke <var title="">errorCallback</var> with
          <var title="">error</var> as its argument.</p>
        </li>
      </ol>

      <p>The task source for these <span title="concept-task">tasks</span>
      is the user interaction task source.</p>
    </dd>
  </dl>

  <div title='Navigator implements NavigatorUserMedia' class='idl'></div>
  </section>

  <section>
  <h2>MediaStreamOptions</h2>

  <dl title='[NoInterfaceObject] interface MediaStreamOptions' class='idl'>
    <dt>attribute boolean audio</dt>
    <dd>Set to false if an audio track is not required, default is true</dd>

    <dt>attribute boolean video</dt>
    <dd>Set to false if a video track is not required, default is true</dd>
  </dl>
  </section>

  <section>
  <h2>NavigatorUserMediaSuccessCallback</h2>

  <dl title=
  '[Callback=FunctionOnly, NoInterfaceObject] interface NavigatorUserMediaSuccessCallback'
  class='idl'>
    <dt>void handleEvent(in LocalMediaStream stream)</dt>

    <dd>(Explanation of handleEvent TBD)</dd>
  </dl>
  </section>

  <section>
  <h2>NavigatorUserMediaError and NavigatorUserMediaErrorCallback</h2>

  <dl title='[NoInterfaceObject] interface NavigatorUserMediaError' class='idl'>
    <dt>const unsigned short PERMISSION_DENIED = 1</dt>

    <dd>The user denied the page permission to use the user's media devices.</dd>

    <dt>readonly attribute unsigned short code</dt>

    <dd>Returns the current error's error code. At this time, this will always be 1, for
    which the constant <code title=
    'dom-NavigatorUserMediaError-PERMISSION_DENIED'><a href=
    "#dom-navigatorusermediaerror-permission_denied">PERMISSION_DENIED</a></code> is
    defined.</dd>
  </dl>

  <dl title=
  '[Callback=FunctionOnly, NoInterfaceObject] interface NavigatorUserMediaErrorCallback'
  class='idl'>
    <dt>void handleEvent(in NavigatorUserMediaError error)</dt>

    <dd>(Explanation of handleEvent TBD)</dd>
  </dl>
  </section>
  </section>

  <section>
  <h3>Examples</h3>

  <div class="example">
    <p>A voice chat feature in a game could attempt to get access to the user's
    microphone by calling the API as follows:</p>
    <pre>
&lt;script&gt;
 navigator.getUserMedia('audio', gotAudio);
 function gotAudio(stream) {
   // ... use 'stream' ...
 }
&lt;/script&gt;
</pre>
  </div>

  <div class="example">
    <p>A video-conferencing system would ask for both audio and video:</p>
    <pre>
&lt;script&gt;
 function beginCall() {
   navigator.getUserMedia('audio,video user', gotStream);
 }
 function gotStream(stream) {
   // ... use 'stream' ...
 }
&lt;/script&gt;
</pre>
  </div>
  </section>
  </section>

  <section>
  <h2>Stream API</h2>

  <section>
  <h3>Introduction</h3>

  <p>The <code><a href="#mediastream">MediaStream</a></code> interface is used to
  represent streams of media data, typically (but not necessarily) of audio and/or video
  content, e.g. from a local camera or a remote site. The data from a <code><a href=
  "#mediastream">MediaStream</a></code> object does not necessarily have a canonical
  binary form; for example, it could just be "the video currently coming from the user's
  video camera". This allows user agents to manipulate media streams in whatever fashion
  is most suitable on the user's platform.</p>

  <p>Each <code><a href="#mediastream">MediaStream</a></code> object can represent zero
  or more tracks, in particular audio and video tracks. Tracks can contain multiple
  channels of parallel data; for example a single audio track could have nine channels of
  audio data to represent a 7.2 surround sound audio track.</p>

  <p>Each track represented by a <code><a href="#mediastream">MediaStream</a></code>
  object has a corresponding <code><a href=
  "#mediastreamtrack">MediaStreamTrack</a></code> object.</p>

  <p>A <code><a href="#mediastream">MediaStream</a></code> object has an input and an
  output. The input depends on how the object was created: a <code><a href=
  "#localmediastream">LocalMediaStream</a></code> object generated by a <code title=
  'dom-navigator-getUserMedia'><a href=
  "#dom-navigator-getusermedia">getUserMedia()</a></code> call, for instance, might take
  its input from the user's local camera, while a <code><a href=
  "#mediastream">MediaStream</a></code> created by a <code><a href=
  "#peerconnection">PeerConnection</a></code> object will take as input the data received
  from a remote peer. The output of the object controls how the object is used, e.g. what
  is saved if the object is written to a file, what is displayed if the object is used in
  a <code>video</code> element, or indeed what is transmitted to a remote peer if the
  object is used with a <code><a href="#peerconnection">PeerConnection</a></code>
  object.</p>

  <p>Each track in a <code><a href="#mediastream">MediaStream</a></code> object can be
  disabled, meaning that it is muted in the object's output. All tracks are initially
  enabled.</p>

  <p id='finishedMute'>A <code><a href="#mediastream">MediaStream</a></code> can be
  <a href="#concept-stream-finished" title="concept-stream-finished">finished</a>,
  indicating that its inputs have forever stopped providing data. When a <code><a href=
  "#mediastream">MediaStream</a></code> object is finished, all its tracks are muted
  regardless of whether they are enabled or disabled.</p>

  <p>The output of a <code><a href="#mediastream">MediaStream</a></code> object must
  correspond to the tracks in its input. Muted audio tracks must be replaced with
  silence. Muted video tracks must be replaced with blackness.</p>

  <p>A new <code><a href="#mediastream">MediaStream</a></code> object can be created
  from a list of <code><a href="#mediastreamtrack">MediaStreamTrack</a></code> objects
  using the <code title='dom-MediaStream'><a href="#dom-mediastream">MediaStream()</a>
  </code> constructor. The list of <code><a href="#mediastreamtrack">MediaStreamTrack</a>
  </code> objects can be the track list of another stream, a subset of the track list of
  a stream or a composition of <code><a href="#mediastreamtrack">MediaStreamTrack</a>
  </code> objects from different <code><a href="#mediastream">MediaStream</a></code> objects.

  <p><img alt="" src='images/media-stream-1.png' /></p><!-- no alt since
  it's all described in the previous paragraphs: this is just a
  summary -->
  <!--
c.clearRect(0, 0, 640, 480);
c.save();
try {
  with (c) {
    save();
    strokeStyle = '#AA0000';
    lineWidth = 20;
    beginPath();
    moveTo(50,98);
    lineTo(550, 98);
    stroke();
  }
  mediaStream(c,50,10, true);

} finally {
  c.restore();
}

function cameraIcon(c,x,y) {
  with (c) { save(); try {
    translate(x,y);
    fillRect(-10,-10,20,20);
    beginPath();
    moveTo(7,0);
    lineTo(20,-10);
    lineTo(20,10);
    fill();
    font = '100 8px "Press Start 2P", sans-serif';
    textAlign = 'center';
    textBaseline = 'top';
    fillText('Camera', 4, 15);
  } finally { restore(); } }
}

function mediaStream(c,x,y,vid) {
  with (c) {
    save();
    translate(x-10,y-97);

    // cable
    fillStyle = 'black';
    font = '100 10px "Press Start 2P", sans-serif';
    textAlign = 'right';
    fillText('Input', 95, 170);
    textAlign = 'left';
    fillText('Output', 407, 170);

    // media stream
    fillStyle = '#EE8800';
    strokeStyle = '#FFCC00';
    lineWidth = 6;
    fillRect(100,100,300,170);
    strokeRect(100,100,300,170);
    fillStyle = 'black';
    font = '900 12px "Press Start 2P", sans-serif';
    textAlign = 'left';
    fillText('MediaStream', 110, 123);

    // tracks
    textAlign = 'left';
    strokeStyle = '#CC3300';
    fillStyle = '#FFFF00';
    lineWidth = 4;
    globalAlpha = vid ? 1 : 0.4;
    fillRect(120,140,100,110);
    strokeRect(120,140,100,110);
    globalAlpha = 1;
    fillRect(238,140,100,110);
    strokeRect(238,140,100,110);
    fillStyle = 'black';
    font = '900 10px "Press Start 2P", sans-serif';
    globalAlpha = vid ? 1 : 0.4;
    fillText('Track', 123, 155);
    fillText('(video)', 123, 170);
    globalAlpha = 1;
    fillText('Track', 241, 155);
    fillText('(stereo', 241, 170);
    fillText(' audio)', 241, 185);

    // channels
    strokeStyle = '#999999';
    fillStyle = '#FFFFFF';
    lineWidth = 2;
    fillRect(245,191,86,23);
    strokeRect(245,191,86,23);
    fillRect(245,220,86,23);
    strokeRect(245,220,86,23);
    fillStyle = 'black';
    font = '100 8px "Press Start 2P", sans-serif';
    textAlign = 'left';
    textBaseline = 'alphabetic';
    fillText('left', 249, 202);
    fillText('channel', 249, 211);
    fillText('right', 249, 231);
    fillText('channel', 249, 240);

    // track check marks
    fillStyle = 'black';
    font = '900 35px "Lucida Grande", sans-serif';
    textAlign = 'center';
    textBaseline = 'middle';
    fillText(vid ? '\u2713' : '\u2716', 220, 245);
    fillText('\u2713', 338, 245);

    restore();
  }
}
-->

  <p>The ability to duplicate a <code><a href="#mediastream">MediaStream</a></code>, i.e.
  create a new <code><a href="#mediastream">MediaStream</a></code> object from the track
  list of an existing stream, allows for greater control since separate <code>
  <a href="#mediastream">MediaStream</a></code> instances can be manipulated and consumed
  individually. This can be used, for instance, in a video-conferencing scenario to display
  the local video from the user's camera and microphone in a local monitor, while only
  transmitting the audio to the remote peer (e.g. in response to the user using a "video
  mute" feature). Combining tracks from different <code><a href="#mediastream">MediaStream</a>
  </code> objects into a new <code><a href="#mediastream">MediaStream</a></code> makes it
  possible to, e.g., record selected tracks from a conversation involving several <code>
  <a href="#mediastream">MediaStream</a></code> objects with a single <code>
  <a href="#mediastreamrecorder">MediaStreamRecorder</a></code>.</p>

  <!--
c.clearRect(0, 0, 640, 480);
c.save();
try {
  with (c) {
    save();
    strokeStyle = '#AA0000';
    lineWidth = 20;
    beginPath();
    moveTo(50,98);
    lineTo(550, 98);
    lineTo(550, 210);
    lineTo(50, 210);
    lineTo(50, 320);
    lineTo(550, 320);
    lineTo(550,420);
    stroke();
    beginPath();
    moveTo(50,320);
    lineTo(50,420);
    stroke();
    restore();
    fillStyle = 'black';
    font = '100 10px "Press Start 2P", sans-serif';
    textAlign = 'center';
    fillText('<video>', 50, 440);
    fillText('PeerConnection', 550, 440);
    font = '100 8px "Press Start 2P", sans-serif';
  }
  cameraIcon(c,25,98)
  mediaStream(c,50,10, true);
  mediaStream(c,50,233, false);

  with (c) {
    font = '100 8px "Press Start 2P", sans-serif';
    textAlign = 'left';
    textBaseline = 'middle';
    fillStyle = 'gray';

    fillText('from', 4, 130);
    fillText('getUserMedia()', 4, 140);

    fillText('via URL.getObjectURL()', 4, 450);

    textAlign = 'center';
    fillText('via addStream()', 550, 450);
  }
} finally {
  c.restore();
}

function cameraIcon(c,x,y) {
  with (c) { save(); try {
    translate(x,y);
    fillRect(-10,-10,20,20);
    beginPath();
    moveTo(7,0);
    lineTo(20,-10);
    lineTo(20,10);
    fill();
    font = '100 8px "Press Start 2P", sans-serif';
    textAlign = 'center';
    textBaseline = 'top';
    fillText('Camera', 4, 15);
  } finally { restore(); } }
}

function mediaStream(c,x,y,vid) {
  with (c) {
    save();
    translate(x-10,y-97);

    // cable
    fillStyle = 'black';
    font = '100 10px "Press Start 2P", sans-serif';
    textAlign = 'right';
    fillText('Input', 95, 170);
    textAlign = 'left';
    fillText('Output', 407, 170);

    // media stream
    fillStyle = '#EE8800';
    strokeStyle = '#FFCC00';
    lineWidth = 6;
    fillRect(100,100,300,170);
    strokeRect(100,100,300,170);
    fillStyle = 'black';
    font = '900 12px "Press Start 2P", sans-serif';
    textAlign = 'left';
    fillText(!vid ? 'MediaStream' : 'LocalMediaStream', 110, 123);

    // tracks
    textAlign = 'left';
    strokeStyle = '#CC3300';
    fillStyle = '#FFFF00';
    lineWidth = 4;
    globalAlpha = vid ? 1 : 0.4;
    fillRect(120,140,100,110);
    strokeRect(120,140,100,110);
    globalAlpha = 1;
    fillRect(238,140,100,110);
    strokeRect(238,140,100,110);
    fillStyle = 'black';
    font = '900 10px "Press Start 2P", sans-serif';
    globalAlpha = vid ? 1 : 0.4;
    fillText('Track', 123, 155);
    fillText('(video)', 123, 170);
    globalAlpha = 1;
    fillText('Track', 241, 155);
    fillText('(stereo', 241, 170);
    fillText(' audio)', 241, 185);

    // channels
    strokeStyle = '#999999';
    fillStyle = '#FFFFFF';
    lineWidth = 2;
    fillRect(245,191,86,23);
    strokeRect(245,191,86,23);
    fillRect(245,220,86,23);
    strokeRect(245,220,86,23);
    fillStyle = 'black';
    font = '100 8px "Press Start 2P", sans-serif';
    textAlign = 'left';
    textBaseline = 'alphabetic';
    fillText('left', 249, 202);
    fillText('channel', 249, 211);
    fillText('right', 249, 231);
    fillText('channel', 249, 240);

    // track check marks
    fillStyle = 'black';
    font = '900 35px "Lucida Grande", sans-serif';
    textAlign = 'center';
    textBaseline = 'middle';
    fillText(vid ? '\u2713' : '\u2716', 220, 245);
    fillText('\u2713', 338, 245);

    restore();
  }
}
-->

  <p>The <code><a href="#localmediastream">LocalMediaStream</a></code> interface is used
  when the user agent is generating the stream's data (e.g. from a camera or streaming it
  from a local video file). It allows authors to control individual tracks during the
  generation of the content, e.g. to allow the user to temporarily disable a local camera
  during a video-conference chat.</p>

  <p>When a <code><a href="#localmediastream">LocalMediaStream</a></code> object is being
  generated from a local file (as opposed to a live audio/video source), the user agent
  should stream the data from the file in real time, not all at once. This reduces the
  ease with which pages can distinguish live video from pre-recorded video, which can
  help protect the user's privacy.</p>
  </section>
  <section>
  <h3>Interface definitions</h3>

  <section>
  <h4>MediaStream</h4>

  <p>The <dfn id='dom-mediastream' title='dom-MediaStream'><code>MediaStream(<var title=
  "">trackList</var>)</code></dfn> constructor must return a new <code><a href=
  "#mediastream">MediaStream</a></code> object with a newly generated label.
  A new <code><a href="#mediastreamtrack">MediaStreamTrack</a></code> object is created
  for every unique underlying media source in <var title="">trackList</var> and appended
  to the new <code><a href="#mediastream">MediaStream</a></code> object's track list
  according to the track ordering constraints.

  <p>A <code><a href="#mediastream">MediaStream</a></code> object is said to <em>end</em>
  when the user agent learns that no more data will ever be forthcoming for this
  stream.</p>

  <p>When a <code><a href="#mediastream">MediaStream</a></code> object ends for any
  reason (e.g. because the user rescinds the permission for the page to use the local
  camera, or because the data comes from a finite file and the file's end has been
  reached and the user has not requested that it be looped, or because the stream comes
  from a remote peer and the remote peer has permanently stopped sending data, it is
  said to be <dfn id='concept-stream-finished' title='concept-stream-finished'>finished
  </dfn>. When this happens for any reason other than the <code title='dom-MediaStream-stop'>
  <a href="#dom-mediastream-stop">stop()</a></code> method being invoked, the user agent must
  queue a task that runs the following steps:</p>

  <ol>
    <li>
      <p>If the object's <code title='dom-MediaStream-readyState'><a href=
      "#dom-mediastream-readystate">readyState</a></code> attribute has the value
      <code title='dom-MediaStream-ENDED'><a href=
      "#dom-mediastream-ended">ENDED</a></code> (2) already, then abort these steps. (The
      <code title='dom-MediaStream-stop'><a href=
      "#dom-mediastream-stop">stop()</a></code> method was probably called just before
      the stream stopped for other reasons, e.g. the user clicked an in-page stop button
      and then the user-agent-provided stop button.)</p>
    </li>

    <li>
      <p>Set the object's <code title='dom-MediaStream-readyState'><a href=
      "#dom-mediastream-readystate">readyState</a></code> attribute to <code title=
      'dom-MediaStream-ENDED'><a href="#dom-mediastream-ended">ENDED</a></code> (2).</p>
    </li>

    <li>
      <p>Fire a simple event named <code title=
      'event-MediaStream-ended'><a href="#event-mediastream-ended">ended</a></code> at
      the object.</p>
    </li>
  </ol>

  <p>As soon as a <code><a href="#mediastream">MediaStream</a></code> object is <a href=
  "#concept-stream-finished" title="concept-stream-finished">finished</a>, the stream's
  tracks start outputting only silence and/or blackness, as appropriate, <a href=
  "#finishedMute">as defined earlier</a>.</p>

  <p>If the end of the stream was reached due to a user request, the task
  source for this <span title='concept-task'>task</span> is the user
  interaction task source. Otherwise the task source for this
  <span title='concept-task'>task</span> is the networking task source.</p>

  <dl title='[Constructor (in MediaStreamTrackList trackList)] interface MediaStream' class=
  'idl'>
    <dt>readonly attribute DOMString label</dt>

    <dd>Returns a label that is unique to this stream, so that streams can be recognized
    after they are sent through the <code><a href=
    "#peerconnection">PeerConnection</a></code> API.</dd>

    <dt>readonly attribute MediaStreamTrackList tracks</dt>

    <dd>
      <p>Returns a <code><a href="#mediastreamtracklist">MediaStreamTrackList</a></code>
      object representing the tracks that can be enabled and disabled.</p>

      <p>A <code><a href="#mediastream">MediaStream</a></code> can have multiple audio
      and video sources (e.g. because the user has multiple microphones, or because the
      real source of the stream is a <a href="#media-resource">media resource</a> with
      many media tracks). The stream represented by a <code><a href=
      "#mediastream">MediaStream</a></code> thus has zero or more tracks.</p>

      <p>The <dfn id='dom-mediastream-tracks' title=
      'dom-MediaStream-tracks'><code>tracks</code></dfn> attribute must return an
      <span title="array host objects">array host object</span> for objects of type
      <code><a href="#mediastreamtrack">MediaStreamTrack</a></code> that is <em>fixed
      length</em> and <em>read only</em>. The same object must be returned each time the
      attribute is accessed. [[!WEBIDL]]</p>

      <p>The array must contain the <code><a href=
      "#mediastreamtrack">MediaStreamTrack</a></code> objects that correspond to the the
      tracks of the stream. The relative order of all tracks in a user agent must be
      stable. All audio tracks must precede all video tracks. Tracks that come from a
      <a href="#media-resource">media resource</a> whose format defines an order must be
      in the order defined by the format; tracks that come from a <a href=
      "#media-resource">media resource</a> whose format does not define an order must be
      in the relative order in which the tracks are declared in that <a href=
      "#media-resource">media resource</a>. Within these constraints, the order is
      user-agent defined.</p>
    </dd>

    <dt>MediaStreamRecorder record()</dt>

    <dd>
      <p>Begins recording the stream. The returned <code><a href=
      "#mediastreamrecorder">MediaStreamRecorder</a></code> object provides access to the
      recorded data.</p>

      <p>When the <dfn id='dom-mediastream-record' title=
      'dom-MediaStream-record'><code>record()</code></dfn> method is invoked, the user
      agent must return a new <code><a href=
      "#mediastreamrecorder">MediaStreamRecorder</a></code> object associated with the
      stream.</p>
    </dd>

    <dt>const unsigned short LIVE = 1</dt>

    <dd>The stream is active (the user agent is making a best-effort attempt to receive
    or generate data in real time).</dd>

    <dt>const unsigned short ENDED = 2</dt>

    <dd>The stream has finished (the user agent is no longer receiving or generating
    data, and will never receive or generate more data for this stream).</dd>

    <dt>readonly attribute unsigned short readyState</dt>

    <dd>
      <p>The <dfn id='dom-mediastream-readystate' title=
      'dom-MediaStream-readyState'><code>readyState</code></dfn> attribute represents the
      state of the stream. It must return the value to which the user agent last set it
      (as defined below). It can have the following values: <dfn>LIVE</dfn> or
      <dfn>ENDED</dfn>.</p>

      <p>When a <code><a href="#mediastream">MediaStream</a></code> object is created,
      its <code title='dom-MediaStream-readyState'><a href=
      "#dom-mediastream-readystate">readyState</a></code> attribute must be set to
      <code title='dom-MediaStream-LIVE'><a href="#dom-mediastream-live">LIVE</a></code>
      (1), unless it is being created using the <code title='dom-MediaStream'><a href=
      "#dom-mediastream">MediaStream()</a></code> constructor whose argument is a list of
      <code><a href="#mediastreamtrack">MediaStreamTrack</a></code> objects whose underlying
      media sources will never produce any more data, in which case the <code><a href=
      "#mediastream">MediaStream</a></code> object must be created with its <code title=
      'dom-MediaStream-readyState'><a href=
      "#dom-mediastream-readystate">readyState</a></code> attribute set to <code title=
      'dom-MediaStream-ENDED'><a href="#dom-mediastream-ended">ENDED</a></code> (2).</p>
    </dd>

    <dt>attribute Function? onended</dt>

    <dd>This event handler, of type <code title='event-MediaStream-ended'><a href=
    "#event-mediastream-ended">ended</a></code>, must be supported by all objects
    implementing the <code><a href="#mediastream">MediaStream</a></code> interface.</dd>
  </dl>

  <div title='MediaStream implements EventTarget' class='idl'></div>
  </section>

  <section>
  <h4>LocalMediaStream</h4>

  <dl title='interface LocalMediaStream : MediaStream' class='idl'>
    <dt>void stop()</dt>

    <dd>
      <p>When a <code><a href="#localmediastream">LocalMediaStream</a></code> object's
      <dfn id='dom-mediastream-stop' title=
      'dom-MediaStream-stop'><code>stop()</code></dfn> method is invoked, the user agent
      must queue a task that runs the following steps:</p>

      <ol>
        <li>
          <p>If the object's <code title='dom-MediaStream-readyState'><a href=
          "#dom-mediastream-readystate">readyState</a></code> attribute is in the
          <code title='dom-MediaStream-ENDED'><a href=
          "#dom-mediastream-ended">ENDED</a></code> (2) state, then abort these
          steps.</p>
        </li>

        <li>
          <p>Permanently stop the generation of data for the stream. If the data is being
          generated from a live source (e.g. a microphone or camera), and no other stream
          is being generated from a live source, then the user agent should remove any
          active "on-air" indicator. If the data is being generated from a prerecorded
          source (e.g. a video file), any remaining content in the file is ignored. The
          stream is <a href="#concept-stream-finished" title=
          "concept-stream-finished">finished</a>. The stream's tracks start outputting
          only silence and/or blackness, as appropriate, <a href="#finishedMute">as
          defined earlier</a>.</p>
        </li>

        <li>
          <p>Set the object's <code title='dom-MediaStream-readyState'><a href=
          "#dom-mediastream-readystate">readyState</a></code> attribute to <code title=
          'dom-MediaStream-ENDED'><a href="#dom-mediastream-ended">ENDED</a></code>
          (2).</p>
        </li>

        <li>
          <p>Fire a simple event named <code title=
          'event-MediaStream-ended'><a href="#event-mediastream-ended">ended</a></code>
          at the object.</p>
        </li>
      </ol>

      <p>The task source for the <span title='concept-task'>tasks</span>
      queued for the <code title='dom-MediaStream-stop'><a href=
      "#dom-mediastream-stop">stop()</a></code> method is the DOM manipulation task
      source.</p>
    </dd>
  </dl>
  </section>

  <section>
  <h4>MediaStreamTrack</h4>

  <div title='typedef MediaStreamTrack[] MediaStreamTrackList' class='idl'></div>

  <dl title='interface MediaStreamTrack' class='idl'>
    <dt>readonly attribute DOMString kind</dt>

    <dd>
      <p>The <dfn id='dom-mediastreamtrack-kind' title=
      'dom-MediaStreamTrack-kind'><code>MediaStreamTrack.kind</code></dfn> attribute must
      return the string "<code title='""'>audio</code>" if the object's corresponding
      track is or was an audio track, "<code title='""'>video</code>" if the
      corresponding track is or was a video track, and a user-agent defined string
      otherwise.</p>
    </dd>

    <dt>readonly attribute DOMString label</dt>

    <dd>
      <p>When a <code><a href="#localmediastream">LocalMediaStream</a></code> object is
      created, the user agent must generate a globally unique identifier string, and must
      initialize the object's <code title='dom-MediaStream-label'><a href=
      "#dom-mediastream-label">label</a></code> attribute to that string. Such strings
      must only use characters in the ranges U+0021, U+0023 to U+0027, U+002A to U+002B,
      U+002D to U+002E, U+0030 to U+0039, U+0041 to U+005A, U+005E to U+007E, and must be
      36 characters long.</p><!-- UUIDs have 36 characters
  including hyphens; the ranges above comes from RFC4574 (the a=label:
  thing in SDP) -->

      <p>When a <code><a href="#mediastream">MediaStream</a></code> is created to
      represent a stream obtained from a remote peer, the <code title=
      'dom-MediaStream-label'><a href="#dom-mediastream-label">label</a></code> attribute
      is initialized from information provided by the remote source.</p>
      <!-- described below
  -->

      <p>When a <code><a href="#mediastream">MediaStream</a></code> is created from
      another using the <code title='dom-MediaStream'><a href=
      "#dom-mediastream">MediaStream()</a></code> constructor, the <code title=
      'dom-MediaStream-label'><a href="#dom-mediastream-label">label</a></code> attribute
      is initialized to a newly generated value.</p><!-- described above -->

      <p>The <dfn id='dom-mediastream-label' title=
      'dom-MediaStream-label'><code>label</code></dfn> attribute must return the value to
      which it was initialized when the object was created.</p>

      <p class='note'>The label of a <code><a href="#mediastream">MediaStream</a></code>
      object is unique to the source of the stream, but that does not mean it is not
      possible to end up with duplicates. For example, a locally
      generated stream could be sent from one user to a remote peer using <code><a href=
      "#peerconnection">PeerConnection</a></code>, and then sent back to the original
      user in the same manner, in which case the original user will have multiple streams
      with the same label (the locally-generated one and the one received from the remote
      peer).</p>

      <p>User agents may label audio and video sources (e.g. "Internal microphone" or
      "External USB Webcam"). The <dfn id='dom-mediastreamtrack-label' title=
      'dom-MediaStreamTrack-label'><code>MediaStreamTrack.label</code></dfn> attribute
      must return the label of the object's corresponding track, if any. If the
      corresponding track has or had no label, the attribute must instead return the
      empty string.</p>

      <p class='note'>Thus the <code title='dom-MediaStreamTrack-kind'><a href=
      "#dom-mediastreamtrack-kind">kind</a></code> and <code title=
      'dom-MediaStreamTrack-label'><a href="#dom-mediastreamtrack-label">label</a></code>
      attributes do not change value, even if the <code><a href=
      "#mediastreamtrack">MediaStreamTrack</a></code> object is disassociated from its
      corresponding track.</p>
    </dd>

    <dt>attribute boolean enabled</dt>

    <dd>
      <p>The <dfn id='dom-mediastreamtrack-enabled' title=
      'dom-MediaStreamTrack-enabled'><code>MediaStreamTrack.enabled</code></dfn>
      attribute, on getting, must return the last value to which it was set. On setting,
      it must be set to the new value, and then, if the <code><a href=
      "#mediastreamtrack">MediaStreamTrack</a></code> object is still associated with a
      track, must enable the track if the new value is true, and disable it
      otherwise.</p>

      <p class='note'>Thus, after a <code><a href=
      "#mediastreamtrack">MediaStreamTrack</a></code> is disassociated from its track,
      its <code title='dom-MediaStreamTrack-enabled'><a href=
      "#dom-mediastreamtrack-enabled">enabled</a></code> attribute still changes value
      when set, it just doesn't do anything with that new value.</p>
    </dd>
  </dl>
  </section>

  <section>
  <h4>MediaStreamRecorder</h4>

  <dl title='interface MediaStreamRecorder' class='idl'>
    <dt>voice getRecordedData (in BlobCallback? callback)</dt>

    <dd>
      <p>Creates a <code>Blob</code> of the recorded data, and invokes the provided
      callback with that <code>Blob</code>.</p>

      <p>When the <dfn id='dom-mediastreamrecorder-getrecordeddata' title=
      'dom-MediaStreamRecorder-getRecordedData'><code>getRecordedData()</code></dfn>
      method is called, the user agent must run the following steps:</p>

      <ol>
        <li>
          <p>Let <var title="">callback</var> be the callback indicated by the method's
          first argument.</p>
        </li>

        <li>
          <p>If <var title="">callback</var> is null, abort these steps.</p>
        </li><!-- we could throw an exception instead (that's
   why the method doesn't return until later: so that we can add an
   exception here without changing the algorithm) -->

        <li>
          <p>Let <var title="">data</var> be the data that was streamed by the
          <code><a href="#mediastream">MediaStream</a></code> object from which the
          <code><a href="#mediastreamrecorder">MediaStreamRecorder</a></code> was created
          since the creation of the <code><a href=
          "#mediastreamrecorder">MediaStreamRecorder</a></code> object.</p>
        </li>

        <li>
          <p>Return, and run the remaining steps asynchronously.</p>
        </li>

        <li>
          <p>Generate a file that containing <var title="">data</var> in a format
          supported by the user agent for use in <code>audio</code> and
          <code>video</code> elements.</p>
        </li>

        <li>
          <p>Let <var title="">blob</var> be a <code>Blob</code> object representing the
          contents of the file generated in the previous step. [[!FILE-API]]</p>
        </li>

        <li>
          <p>Queue a task to invoke <var title="">callback</var> with
          <var title="">blob</var> as its argument.</p>
        </li>
      </ol>

      <p class='note'>The <code title='dom-MediaStreamRecorder-getRecordedData'><a href=
      "#dom-mediastreamrecorder-getrecordeddata">getRecordedData()</a></code> method can
      be called multiple times on one <code><a href=
      "#mediastreamrecorder">MediaStreamRecorder</a></code> object; each time, it will
      create a new file as if this was the first time the method was being called. In
      particular, the method does not stop or reset the recording when the method is
      called.</p>
    </dd>
  </dl>
  </section>

  <section>
  <h4>BlobCallback</h4>

  <dl title='[Callback=FunctionOnly, NoInterfaceObject] interface BlobCallback' class=
  'idl'>
    <dt>void handleEvent (in Blob blob)</dt>

    <dd>Def TBD</dd>
  </dl>
  </section>

  <section>
  <h4>URL</h4>

  <p><em>Note that the following is actually only a partial interface, but ReSpec does
  not yet support that.</em></p>

  <dl title='interface URL' class='idl'>
    <dt>static DOMString createObjectURL (in MediaStream stream)</dt>

    <dd>
      <p>Mints a <a href="#blob-url">Blob URL</a> to refer to the given <code><a href=
      "#mediastream">MediaStream</a></code>.</p>

      <p>When the <dfn id='dom-url-createobjecturl' title=
      'dom-URL-createObjectURL'><code>createObjectURL()</code></dfn> method is called
      with a <code><a href="#mediastream">MediaStream</a></code> argument, the user agent
      must return a unique <a href="#blob-url">Blob URL</a> for the given <code><a href=
      "#mediastream">MediaStream</a></code>. [[!FILE-API]]</p>

      <p>For audio and video streams, the data exposed on that stream must be in a format
      supported by the user agent for use in <code>audio</code> and <code>video</code>
      elements.</p>

      <p class='bookkeeping'>A <dfn id='blob-url'>Blob URL</dfn> is the same as what the
      File API specification calls a Blob URI, except that anything in the
      definition of that feature that refers to <code>File</code> and <code>Blob</code>
      objects is hereby extended to also apply to <code><a href=
      "#mediastream">MediaStream</a></code> and <code><a href=
      "#localmediastream">LocalMediaStream</a></code> objects.</p>
    </dd>
  </dl>
  </section>
  </section>

  <section>
  <h3>Examples</h3>

  <div class="example">
    <p>This sample code exposes a button. When clicked, the button is disabled and the
    user is prompted to offer a stream. The user can cause the button to be re-enabled by
    providing a stream (e.g. giving the page access to the local camera) and then
    disabling the stream (e.g. revoking that access).</p>
    <pre>
&lt;input type="button" value="Start" onclick="start()" id="startBtn"&gt;
&lt;script&gt;
 var startBtn = document.getElementById('startBtn');
 function start() {
   navigator.getUserMedia('audio,video', gotStream);
   startBtn.disabled = true;
 }
 function gotStream(stream) {
   stream.onended = function () {
     startBtn.disabled = false;
   }
 }
&lt;/script&gt;
</pre>
  </div>

  <div class="example">
    <p>This example allows people to record a short audio message and upload it to the
    server. This example even shows rudimentary error handling.</p>
    <pre>
&lt;input type="button" value="⚫" onclick="msgRecord()" id="recBtn"&gt;
&lt;input type="button" value="◼" onclick="msgStop()" id="stopBtn" disabled&gt;
&lt;p id="status"&gt;To start recording, press the ⚫ button.&lt;/p&gt;
&lt;script&gt;
 var recBtn = document.getElementById('recBtn');
 var stopBtn = document.getElementById('stopBtn');
 function report(s) {
   document.getElementById('status').textContent = s;
 }
 function msgRecord() {
   report('Attempting to access microphone...');
   navigator.getUserMedia('audio', gotStream, noStream);
   recBtn.disabled = true;
 }
 var msgStream, msgStreamRecorder;
 function gotStream(stream) {
   report('Recording... To stop, press to ◼ button.');
   msgStream = stream;
   msgStreamRecorder = stream.record();
   stopBtn.disabled = false;
   stream.onended = function () {
     msgStop();     
   }
 }
 function msgStop() {
   report('Creating file...');
   stopBtn.disabled = true;
   msgStream.onended = null;
   msgStream.stop();
   msgStreamRecorder.getRecordedData(msgSave);
 }
 function msgSave(blob) {
   report('Uploading file...');
   var x = new XMLHttpRequest();
   x.open('POST', 'uploadMessage');
   x.send(blob);
   x.onload = function () {
     report('Done! To record a new message, press the ⚫ button.');
     recBtn.disabled = false;
   };
   x.onerror = function () {
     report('Failed to upload message. To try recording a message again, press the ⚫ button.');
     recBtn.disabled = false;
   };
 }
 function noStream() {
   report('Could not obtain access to your microphone. To try again, press the ⚫ button.');
   recBtn.disabled = false;
 }
&lt;/script&gt;
</pre>
  </div>

  <div class="example">
    <p>This example allows people to take photos of themselves from the local video
    camera.</p>
    <pre>
&lt;article&gt;
 &lt;style scoped&gt;
  video { transform: scaleX(-1); }
  p { text-align: center; }
 &lt;/style&gt;
 &lt;h1&gt;Snapshot Kiosk&lt;/h1&gt;
 &lt;section id="splash"&gt;
  &lt;p id="errorMessage"&gt;Loading...&lt;/p&gt;
 &lt;/section&gt;
 &lt;section id="app" hidden&gt;
  &lt;p&gt;&lt;video id="monitor" autoplay&gt;&lt;/video&gt; &lt;canvas id="photo"&gt;&lt;/canvas&gt;
  &lt;p&gt;&lt;input type=button value="&amp;#x1F4F7;" onclick="snapshot()"&gt;
 &lt;/section&gt;
 &lt;script&gt;
  navigator.getUserMedia('video user', gotStream, noStream);
  var video = document.getElementById('monitor');
  var canvas = document.getElementById('photo');
  function gotStream(stream) {
    video.src = URL.getObjectURL(stream);
    video.onerror = function () {
      stream.stop();
    };
    stream.onended = noStream;
    video.onloadedmetadata = function () {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      document.getElementById('splash').hidden = true;
      document.getElementById('app').hidden = false;
    };
  }
  function noStream() {
    document.getElementById('errorMessage').textContent = 'No camera available.';
  }
  function snapshot() {
    canvas.getContext('2d').drawImage(video, 0, 0);
  }
 &lt;/script&gt;
&lt;/article&gt;
</pre>
  </div>
  </section>
  </section>

  <section>
  <h2>Garbage collection</h2>


  </section>

  <section>
  <h2>Event definitions</h2>

-
  </section>

  <section class="informative">
  <h2>Event summary</h2>

  <p>The following event fires on <code><a href="#mediastream">MediaStream</a></code>
  objects:</p>

  <table>
    <tr>
      <th>Event name</th>

      <th>Interface</th>

      <th>Fired when...</th>
    </tr>

    <tbody>
      <tr>
        <td><dfn id='event-mediastream-ended' title=
        'event-MediaStream-ended'><code>ended</code></dfn></td>

        <td><code>Event</code></td>

        <td>The <code><a href="#mediastream">MediaStream</a></code> object will no longer
        stream any data, either because the user revoked the permissions, or because the
        source device has been ejected, or because the remote peer stopped sending data,
        or because the <code title='dom-MediaStream-stop'><a href=
        "#dom-mediastream-stop">stop()</a></code> method was invoked.</td>
      </tr>
    </tbody>
  </table>
  </section>

  <section>
  <h2>Change Log</h2>
  <p> This section will be removed before publication. </p>

  <h3> To Do Items </h3>
  <p> - </p>


  <h3> Nov 9 2011</h3>
  <ol>
    <li> Created first version by copying the webrtc spec and ripping out stuff. Put it on github. </li>
 </ol>
  
  </section>

 
  <section class="appendix">
  <h2>Acknowledgements</h2>

  <p>The editors wish to thank the Working Group chairs, Harald Alvestrand and Stefan
  Håkansson, for their support.</p>
  </section>
</body>
</html>
